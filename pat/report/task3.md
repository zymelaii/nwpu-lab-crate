# 任务说明

基于 SVM 构建机器学习模型，对 Omniglot 中的字符分类。

# 关于数据集

本实验采用的数据集为 [Omniglot Dataset](https://github.com/brendenlake/omniglot)，也称全语言文字数据集。其包含了各种语言的不同字母表，如日语的平假名与片假名，韩语的元音和复印，最常见的 26 个拉丁字母等。该数据集共包含 50 个不同语言的字母表，每个字母表中包含不同的字符总计 1623 种，其中每个字符由 20 个不同的人数学组成 20 个样本。本次实验选取了该数据集中的 200 个字符，并将每种字符的前 15 张图片作为训练集，后 5 张图片作为验证集。

# 方法简介

该数据集中类别数 200 远大于每个类别的样本数 20，属于小样本训练问题。

观察图像数据可以发现图像矩阵为稀疏矩阵，大部分为元素 255，也即图像的大部分为空白区域，故而有必要对图像进行降维提取特征。

同时训练过程中发现模型在训练集的准确率极高，而在验证集上的准确率不足 60%，可以判断模型出现过拟合情况，故采取数据增强方法抑制过拟合的发生。

最终的总体流程如下：

1. 将输入样本的每类样本按 3:1 的比例划分为训练集和验证集
2. 对于训练集的每份样本，随机抽取另一份样本按 0.3 的系数进行 mixup，将训练集样本数扩充一倍
3. 使用特征提取/数据降维方法对样本进行处理，包括 HOG、PCA
4. 以核函数和 C 值为参数空间对 SVM 分类器进行网格搜索，采用 10 折交叉验证方法对模型进行评估
5. 在测试集与验证集上评估模型准确率

# 实验结果

采用不同数据预处理方法时：

|           | 最优交叉验证分数 | 训练集准确率 | 验证集准确率 |
| :-------: | :--------------: | :----------: | :----------: |
|     /     |      0.3786      |     1.0      |    0.4037    |
|    HOG    |      0.5800      |    0.9986    |    0.5875    |
|    PCA    |      0.0895      |    0.1750    |    0.1013    |
|   Mixup   |      0.9339      |     1.0      |    0.3312    |
| HOG+Mixup |      0.8700      |    0.9995    |    0.6150    |

其中取得最优结果 HOG+Mixup 时，SVM 分类器的 C 值为 1.096478196143185，核函数为 3 阶多项式。

应用 HOG，无 Mixup 处理，采用不同训练集、验证集划分时：

|                          | 最优交叉验证分数 | 训练集准确率 | 验证集准确率 |
| :----------------------: | :--------------: | :----------: | :----------: |
| 100% 训练集 + 25% 验证集 |      0.6153      |    0.9803    |    0.9750    |
|           4:1            |      0.5896      |    0.9788    |    0.5950    |
|           3:1            |      0.5932      |    0.9809    |    0.5913    |
|     1:1 五折交叉验证     |      0.4979      |    0.9936    |    0.5594    |

结合两张表可以判断出最终的模型仍存在一定程度的过拟合情况，模型的泛化能力较弱，无法准确学习到图像的关键特征。

使用 HOG 方法提取图像梯度直方图在一定程度上能够提取字形图像的形态特征，通过该特征学习到的模型在验证集上的预测准确率上得到了明显的提升，验证了特征提取的可靠性；而另一种 PCA 主成分分析降维虽然压缩了特征维数，但其作为一种通用算法本身并不关注图像的纹理与结构信息，而字符判断恰巧又最为依赖字形信息，故而能够提取图像边缘与纹理信息的 HOG 方法能够取得较好的效果。

在 HOG 的基础上，使用数据增强的方法对过拟合情形进行抑制。通过 Mixup 将训练集样本数量扩充一倍后，交叉验证的均值分数得到了显著的提升，与此基础上对训练集的预测准确率保持较高程度且验证集的准确率也得到了一定的提升，可以判断数据增强方法对此小样本分类任务具有一定的有效性。

但综合来看，模型的泛化能力仍较为欠缺，综合两张表可以分析出 SVM 针对该规模的分类任务总是能够找到优秀的超平面，故而改进方向应当在于换用更有效的特征提取办法。

# 遇到的问题及解决方法

**问题**

图像直接输如维数过多，且特征不明显，训练后的验证集准确率极低

**方案**

使用 HOG、PCA 等方法提取图像特征，对输入向量进行降维

**问题**

提取特征后验证集准确率仍相对较低，且模型在训练集上呈现出过拟合的趋势。

**方案**

使用 Mixup 数据增强方法扩充训练集样本数量，抑制模型的过拟合
